- # Project Pipeline Logic & Architecture
  
This document explains the *why* behind the scripts.  
- ## Part 1:  `downloader.py`  (Journal Ingestion)
- **Objective:** Download new weekly patent journals (Parts I & II).
- **Challenge:** The website's download links are not simple `<a>` tags. They are `<form>` submissions.
- **Logic:**
	- Uses `requests` (not Selenium) to fetch the raw HTML. This is very fast.
	- Uses `BeautifulSoup` to find all download forms.
	- Finds the correct `FileName` value from the hidden `<input>` field.
	- Mimics a browser by sending a `POST` request with that `FileName` to the correct URL.
	- It saves its progress in `download_history.json` to avoid re-downloading.
- ## Part 2:  `extract.py`  &  `filter.py`  (PDF Parsing)
- **Objective:** Extract structured data from the downloaded PDFs and identify software patents.
- **Logic (`extract.py`):**
	- Uses `PyMuPDF` to open each PDF and extract its raw text content.
	- Uses a large Regular Expression (regex) to find and capture data for each patent (e.g., `(21) Application No.`, `(54) Title...`, etc.).
	- Saves all data to `all_patents.json`.
- **Logic (`filter.py`):**
	- Reads `all_patents.json`.
	- Checks the `(51) International classification` (IPC) field for each patent.
	- **Software Patent Logic:**
		- If the IPC list contains *only* codes like `G06`, it's "Software".
		- If it contains *no* `G06` codes, it's "Non-Software".
		- If it contains a *mix* (e.g., `G06` and `F02D`), it's "Hybrid".
	- Saves the "Software" and "Hybrid" patents to `classified_patents.json`.
- ## Part 3:  `search_requests.py`  (Document Retrieval)
  
  This is the most complex part of the pipeline. It uses a `requests.Session()` to navigate a series of 5+ web pages that are protected by a CAPTCHA and JavaScript redirects.  
- **Objective:** Get the final "View Documents" page for a single patent.
- **Model:** "Human-in-the-Loop." The script handles all network logic; the human just provides the CAPTCHA text.
- ### The Full Request Chain
- **`GET` (Page 1: Search Form):**
	- Gets the search page to acquire session cookies.
	- Finds the CAPTCHA image URL and downloads `captcha.jpg`.
	- Pauses and waits for human input.
- **`POST` (Page 2: Search Results):**
	- **Challenge:** The form is complex and fails if any field is wrong.
	- **Logic:** It constructs a *very specific* 12-field payload that was discovered by manually inspecting the browser's "Network" tab. This payload includes checkboxes, default values, and the user's CAPTCHA text.
	- **Key Finding:** The `POST` must be sent to the `.../Search` URL, not the base URL.
	- **Key Finding:** A `Referer` header *must* be included.
- **`POST` (Page 3: Application Details):**
	- Parses the "Results" page for the hidden form that links to the details.
	- Extracts the `ConnectionName` and `ApplicationNumber` values from that form.
	- `POST`s this new payload to the `.../PatentDetails` URL.
- **`POST` (Page 4: The JS Redirect):**
	- Parses the "Details" page for the "View Application Status" form.
	- `POST`s that form's payload.
	- **Key Finding:** The server returns a 10-line HTML page with an `onload` JavaScript command. `requests` cannot run this.
- **`POST` (Page 5: The ****Real**** Status Page):**
	- **The Bypass:** The script manually parses the "JS Redirect" page.
	- It extracts the *new* hidden values (`AppNumber` and `OTP`) and the *new* `action` URL.
	- It `POST`s this payload, successfully mimicking the JavaScript redirect and landing on the *real* status page.
- **`POST` (Page 6: View Documents):**
	- Parses the *real* status page for the "View Documents" form.
	- Extracts the payload (`APPLICATION_NUMBER` and `SubmitAction`).
	- `POST`s this final payload to get the document list.
	- Saves the final page as `view_documents.html`.
